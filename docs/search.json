[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "LLaMPPL.clj",
    "section": "",
    "text": "1 Preface\nThis repo explores the LLaMPPL underlying algorithms from Clojure using llama.clj.\nSee Sequential Monte Carlo Steering of Large Language Models using Probabilistic Programs by Alexander K. Lew, Tan Zhi-Xuan, Gabriel Grand, Vikash K. Mansinghka (see Figure 1 and Subsection 2.2).\nAt the moment, we demonstrate implementing the Sequential Monte Carlo algoritm on a specific case, the Hard Constraints case generating texts with only short words with a certain choice of M (the Markove kernel) and G (the potential function), not the most efficient one.\nThe main effort so far has been in tackling some of the caching challenges.\n\nsource: notebooks/index.clj",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preface</span>"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "2  Setup",
    "section": "",
    "text": "(ns setup)\n\n(to be documented soon)\n\nsource: notebooks/setup.clj",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "3  A few utility functions",
    "section": "",
    "text": "(ns utils)\n\n\n(defn now []\n  (java.util.Date.))\n\n\nsource: notebooks/utils.clj",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>A few utility functions</span>"
    ]
  },
  {
    "objectID": "llms.html",
    "href": "llms.html",
    "title": "4  LLMs: Using llama.clj",
    "section": "",
    "text": "4.1 Constants\nPath to the LLM:\nOne megabyte:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLMs: Using llama.clj</span>"
    ]
  },
  {
    "objectID": "llms.html#constants",
    "href": "llms.html#constants",
    "title": "4  LLMs: Using llama.clj",
    "section": "",
    "text": "(def llama7b-path\n  (str (System/getenv \"MODELS_PATH\")\n       \"/llama-2-7b-chat.ggmlv3.q4_0.bin\"))\n\n\n\n(def MB (math/pow 2 20))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLMs: Using llama.clj</span>"
    ]
  },
  {
    "objectID": "llms.html#basics",
    "href": "llms.html#basics",
    "title": "4  LLMs: Using llama.clj",
    "section": "4.2 Basics",
    "text": "4.2 Basics\nCreating a new model context:\n\n(defn new-llama-ctx []\n  (llama/create-context\n   llama7b-path\n   {:use-mlock true}))\n\nA copy of an empty model (to extract basic information):\n\n(def base-llama-ctx\n  (new-llama-ctx))\n\nA function to turn a String of text to a list of tokens:\n\n(defn tokenize [text]\n  (llutil/tokenize base-llama-ctx text))\n\nExample:\n\n(delay\n  (-&gt; \"The Fed says\"\n      tokenize))\n\n\n[1576 17972 4083]\n\nA function to turn a list of tokens to a String of text:\n\n(defn untokenize [tokens]\n  (llutil/untokenize base-llama-ctx tokens))\n\nExample:\n\n(delay\n  (-&gt; \"The Fed says\"\n      tokenize\n      untokenize))\n\n\n\"The Fed says\"\n\nA map from tokens to the corresponding strings:\n\n(def token-&gt;str\n  (into (sorted-map)\n        (comp (map\n               (fn [token]\n                 [token (raw/llama_token_to_str base-llama-ctx token)]))\n              (take-while (fn [[token untoken]]\n                            untoken)))\n        (range 0 Integer/MAX_VALUE)))\n\nExample:\n\n(delay\n  (-&gt;&gt; \"The Fed says\"\n       tokenize\n       (map token-&gt;str)))\n\n\n(\"The\" \" Fed\" \" says\")\n\nThe EOS (end-of-sentence) token:\n\n(def llama-eos (llama/eos base-llama-ctx))\n\n\nsource: notebooks/llms.clj",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>LLMs: Using llama.clj</span>"
    ]
  }
]